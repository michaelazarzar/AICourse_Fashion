{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4aa13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\avi\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "Requirement already satisfied: imageio in c:\\users\\avi\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\avi\\anaconda3\\lib\\site-packages (from imageio) (1.20.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\avi\\anaconda3\\lib\\site-packages (from imageio) (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "# WandB â€“ Install the W&B library\n",
    "!pip install wandb -q\n",
    "!pip install opencv-python\n",
    "!pip install imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9d8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import imageio, glob, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf000808",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cce2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the images.\n",
    "train_images_re = np.expand_dims(train_images, axis=3)\n",
    "test_images_re = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "classes = np.unique(train_labels)\n",
    "input_shape = train_images_re[0].shape\n",
    "\n",
    "print(classes)\n",
    "print(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b1e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c32a2b5d8c81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m#img = cv2.imread(item)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#img = cv2.resize(img, (250, 250))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "i = 0\n",
    "for item in train_images[:25]:\n",
    "    print(item[0].shape)\n",
    "    w, h = 28, 28\n",
    "    data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    data[0:28, 0:28] = [item[0], item[1], 0]\n",
    "    #img = cv2.imread(item)\n",
    "    #img = cv2.resize(img, (250, 250))\n",
    "    #plt.axis('off')\n",
    "    #plt.subplot(5, 5, i+1) #.set_title(l)\n",
    "    #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55db394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape, num_classes):\n",
    "    model = keras.Sequential([keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(num_classes)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90006670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(input_shape, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f4b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c706da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 0.6914 - accuracy: 0.7990 - val_loss: 0.4553 - val_accuracy: 0.8403\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 0.3696 - accuracy: 0.8662 - val_loss: 0.3512 - val_accuracy: 0.8685\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 44s 30ms/step - loss: 0.3252 - accuracy: 0.8819 - val_loss: 0.3369 - val_accuracy: 0.8792\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 49s 32ms/step - loss: 0.3001 - accuracy: 0.8897 - val_loss: 0.3433 - val_accuracy: 0.8733\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 49s 32ms/step - loss: 0.2824 - accuracy: 0.8956 - val_loss: 0.3162 - val_accuracy: 0.8875.2824 - accuracy: 0.89\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.2610 - accuracy: 0.9028 - val_loss: 0.3071 - val_accuracy: 0.8873\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.2526 - accuracy: 0.9056 - val_loss: 0.3469 - val_accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 41s 28ms/step - loss: 0.2364 - accuracy: 0.9104 - val_loss: 0.2971 - val_accuracy: 0.8973\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.2239 - accuracy: 0.9153 - val_loss: 0.3051 - val_accuracy: 0.8945\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.2161 - accuracy: 0.9199 - val_loss: 0.3129 - val_accuracy: 0.8937\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images_re, train_labels, epochs=num_epochs, validation_split=0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6143d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.3246 - accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images_re,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78bc8b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Avi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Avi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84912dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
