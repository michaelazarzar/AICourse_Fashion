{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152267b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless==4.5.3.56 --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aa13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB â€“ Install the W&B library\n",
    "!pip install wandb -q\n",
    "!pip install opencv-python==4.1.2.30\n",
    "!pip install imageio\n",
    "!pip install onnxruntime\n",
    "!pip install keras2onnx\n",
    "!pip install tf2onnx\n",
    "!pip install pyyaml h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "import imageio, glob, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf000808",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c6ca9",
   "metadata": {},
   "source": [
    "# Plot head of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4d162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize loaded dataset\n",
    "# plot first few images\n",
    "for i in range(5):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(test_images[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca32cec",
   "metadata": {},
   "source": [
    "# Save images for API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_save = test_images[:5]\n",
    "labels_to_save = test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cafe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images_to_save)):\n",
    "    plt.imshow(images_to_save[i]) \n",
    "    plt.savefig('images/image_' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52e15c",
   "metadata": {},
   "source": [
    "# Remove saved images from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images[5:]\n",
    "test_labels = test_labels[5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e020c",
   "metadata": {},
   "source": [
    "# Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3de2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images.\n",
    "train_images_re = np.expand_dims(train_images, axis=3)\n",
    "test_images_re = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "classes = np.unique(train_labels)\n",
    "input_shape = train_images_re[0].shape\n",
    "\n",
    "print(classes)\n",
    "print(input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d912ac",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55db394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape, num_classes):\n",
    "    model = Sequential([keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(num_classes)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90006670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(input_shape, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f484f5",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4444ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images_re, train_labels, epochs=num_epochs, validation_split=0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6143d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images_re,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a9657",
   "metadata": {},
   "source": [
    "# Save model to .onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a016c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model,\n",
    "                                           #input_sig,\n",
    "                                           opset=13)\n",
    "\n",
    "onnx.save(onnx_model, 'models/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84912dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model('models/model.h5')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9b6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
